# 大文件分片上传

> 大文件分片上传是一种将大文件分割成多个小块（分片）分别上传，最后在服务器端合并的技术方案，用于解决大文件上传中的各种问题。


### 为什么需要分片上传

* **解决大文件上传超时问题**：避免网络请求超时导致整个文件上传失败

* **实现断点续传**：上传中断后可从中断点继续上传

* **提高上传成功率**：减少单次请求失败导致的整体失败

* **优化内存占用**：避免浏览器或服务器一次性加载整个大文件

* **提升上传速度**：可并行上传多个分片

### 核心流程

1. **文件分片**：将文件切割成多个固定大小的块
2. **分片上传**：分别上传每个分片到服务器
3. **分片验证**：服务器校验分片完整性和顺序
4. **文件合并**：服务器将所有分片按顺序合并为完整文件
5. **清理工作**：删除临时分片文件

### 关键技术点解析

#### 文件分片

将大文件切割成多个小块，避免一次性加载到内存。

```js
const chunkSize = 5 * 1024 * 1024; // 5MB
const chunks = [];

for (let start = 0; start < file.size; start += chunkSize) {
  const chunk = file.slice(start, start + chunkSize);
  chunks.push(chunk);
}
```


#### 计算文件哈希值（用于秒传）

使用 `FileReader` + `SparkMD5` 等库计算文件唯一标识（如MD5），判断是否已上传过。

由于文件比较大的情况下，根据读取文件计算哈希值会比较耗时，所以需要放到 `web-worker` 中计算。

```js
import SparkMD5 from 'spark-md5';

self.onmessage = function(e) {
  const { file, chunkSize } = e.data;
  const spark = new SparkMD5.ArrayBuffer();
  const reader = new FileReader();
  const totalChunks = Math.ceil(file.size / chunkSize);
  let currentChunk = 0;

  reader.onload = function(e) {
    spark.append(e.target.result);
    currentChunk++;

    // 发送进度
    self.postMessage({
      type: 'progress',
      progress: (currentChunk / totalChunks) * 100
    });

    if (currentChunk < totalChunks) {
      loadNext();
    } else {
      // 计算完成
      const hash = spark.end();
      self.postMessage({
        type: 'complete',
        hash: hash
      });
    }
  };

  reader.onerror = function() {
    self.postMessage({
      type: 'error',
      error: '读取文件失败'
    });
  };

  function loadNext() {
    const start = currentChunk * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    reader.readAsArrayBuffer(file.slice(start, end));
  }

  loadNext();
};
```

#### 秒传逻辑

基于文件 MD5 判断文件是否已存在。

```js
const fileHash = await calculateHash(file);
const { uploaded } = await checkFileExists(fileHash); // 调用后端接口

if (uploaded) {
  alert('秒传成功！');
  return;
}
```

### 断点续传

记录那些分片已上传，上传中断后可从断点继续。

可以通过查询接口获取已上传的分片，并跳过已上传的分片。

前端可以将切片存放在 `localStorage` 或者 `indexedDB` 中，实现跨会话续传。

```js
const { uploadedChunks } = await getUploadedChunks(fileHash);
for (let i = 0; i < chunks.length; i++) {
  if (uploadedChunks.includes(i)) {
    continue;
  } else {
    await uploadChunk(chunks[i], i);
  }
}
```

### 并发控制（避免请求过多）

限制同时上传的分片数量（如最多四个），避免浏览器崩溃。

```js
async function uploadChunks(chunks, maxConcurrency = 4) {
  const promises = [];
  const pool = [];
  for (let i = 0; i < chunks.length; i++) {
    const p = uploadChunk(chunks[i], i).catch(err => {
      console.error(`分片 ${i} 上传失败`, err);
    });
    promises.push(p);
    pool.push(p);
    if (pool.length >= maxConcurrency) {
      await Promise.race(pool); // 等待任意一个完成
      pool.shift();
    }
  }
  await Promise.all(promises);
}
```

### 进度条与用户体验

```js
let uploadedSize = 0;

function onChunkUploaded(chunkSize) {
  uploadedSize += chunkSize;
  const progress = (uploadedSize / file.size) * 100;
  updateProgress(progress); // 更新 UI
}
```

### 其他优化点

- 切片的时候，主进程做可能会卡顿，放到 `web-worker` 多线程进行计算 MD5 值，文件切片
- 切完之后，将 blob，存储到 IndexedDB 中（可以缓存切片结果，下次上传的时候，从缓存中读取，避免重复计算），然后通过 `web-worker` 的 `postMessage` 发送切片结果给主进程，主进程收到后进行分片上传
- 还可以通过 websocket 实时通知和请求序列的控制速率

